{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb566fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/envs/msds682-new/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1224, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/envs/msds682-new/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/anaconda3/envs/msds682-new/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1228, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org.apache.flink.streaming.api.environment.StreamExecutionEnvironment does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyflink\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatastream\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpointing_mode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointingMode\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Stream environment\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m env = \u001b[43mStreamExecutionEnvironment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_execution_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m env.enable_checkpointing(\u001b[32m10000\u001b[39m)  \u001b[38;5;66;03m# Every 10 seconds\u001b[39;00m\n\u001b[32m      8\u001b[39m env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-new/lib/python3.11/site-packages/pyflink/datastream/stream_execution_environment.py:889\u001b[39m, in \u001b[36mStreamExecutionEnvironment.get_execution_environment\u001b[39m\u001b[34m(configuration)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[33;03mCreates an execution environment that represents the context in which the\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[33;03mprogram is currently executed. If the program is invoked standalone, this\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    885\u001b[39m \u001b[33;03m:return: The execution environment of the context in which the program is executed.\u001b[39;00m\n\u001b[32m    886\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    887\u001b[39m gateway = get_gateway()\n\u001b[32m    888\u001b[39m JStreamExecutionEnvironment = \u001b[43mgateway\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43morg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflink\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstreaming\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreamExecutionEnvironment\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m configuration:\n\u001b[32m    892\u001b[39m     j_stream_exection_environment = JStreamExecutionEnvironment.getExecutionEnvironment(\n\u001b[32m    893\u001b[39m         configuration._j_configuration)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-new/lib/python3.11/site-packages/py4j/java_gateway.py:1664\u001b[39m, in \u001b[36mJavaPackage.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1661\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaClass(\n\u001b[32m   1662\u001b[39m         answer[proto.CLASS_FQN_START:], \u001b[38;5;28mself\u001b[39m._gateway_client)\n\u001b[32m   1663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m does not exist in the JVM\u001b[39m\u001b[33m\"\u001b[39m.format(new_fqn))\n",
      "\u001b[31mPy4JError\u001b[39m: org.apache.flink.streaming.api.environment.StreamExecutionEnvironment does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import StreamTableEnvironment\n",
    "from pyflink.datastream.checkpointing_mode import CheckpointingMode\n",
    "\n",
    "# Stream environment\n",
    "env = StreamExecutionEnvironment.get_execution_environment()\n",
    "env.enable_checkpointing(10000)  # Every 10 seconds\n",
    "env.get_checkpoint_config().set_checkpointing_mode(CheckpointingMode.EXACTLY_ONCE)\n",
    "\n",
    "# StreamTableEnvironment inherits checkpointing\n",
    "t_env = StreamTableEnvironment.create(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699eed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pyflink.table.confluent import ConfluentSettings\n",
    "from pyflink.table import TableEnvironment\n",
    "\n",
    "load_dotenv()\n",
    "settings = ConfluentSettings.from_global_variables()\n",
    "env = TableEnvironment.create(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256df51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5303346e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TableException",
     "evalue": "org.apache.flink.table.api.TableException: Failed to execute sql\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeQueryOperation(TableEnvironmentImpl.java:1094)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1134)\n\tat org.apache.flink.table.api.internal.TableImpl.execute(TableImpl.java:477)\n\tat io.confluent.flink.plugin.ConfluentTools.printChangelog(ConfluentTools.java:171)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)\n\tat org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: io.confluent.flink.plugin.ConfluentFlinkException: Statement 'table-api-2025-11-20-022347-f1f177f0-43c6-4601-b198-1e01324087c5-api' failed.\nReason: SQL parse failed. Incorrect syntax near the keyword 'OFFSET' at line 5, column 13.\nWas expecting one of:\n    \"CURSOR\" ...\n    \"EXISTS\" ...\n    \"NOT\" ...\n    \"ROW\" ...\n    \"UNIQUE\" ...\n    \"(\" ...\n    \"+\" ...\n    \"-\" ...\n    \"INTERVAL\" ...\n    <UNSIGNED_INTEGER_LITERAL> ...\n    <DECIMAL_NUMERIC_LITERAL> ...\n    <APPROX_NUMERIC_LITERAL> ...\n    <BINARY_STRING_LITERAL> ...\n    <PREFIXED_STRING_LITERAL> ...\n    <QUOTED_STRING> ...\n    <UNICODE_STRING_LITERAL> ...\n    <BIG_QUERY_DOUBLE_QUOTED_STRING> ...\n    <BIG_QUERY_QUOTED_STRING> ...\n    \"TRUE\" ...\n    \"FALSE\" ...\n    \"UNKNOWN\" ...\n    \"NULL\" ...\n    <LBRACE_D> ...\n    <LBRACE_T> ...\n    <LBRACE_TS> ...\n    \"DATE\" ...\n    \"TIME\" ...\n    \"TIMESTAMP\" ...\n    \"?\" ...\n    \"CAST\" ...\n    \"EXTRACT\" ...\n    \"POSITION\" ...\n    \"CONVERT\" ...\n    \"TRANSLATE\" ...\n    \"OVERLAY\" ...\n    \"FLOOR\" ...\n    \"CEIL\" ...\n    \"CEILING\" ...\n    \"SUBSTRING\" ...\n    \"TRIM\" ...\n    \"CLASSIFIER\" ...\n    \"MATCH_NUMBER\" ...\n    \"RUNNING\" ...\n    \"PREV\" ...\n    \"NEXT\" ...\n    \"JSON_EXISTS\" ...\n    \"JSON_VALUE\" ...\n    \"JSON_QUERY\" ...\n    \"JSON_OBJECT\" ...\n    \"JSON_OBJECTAGG\" ...\n    \"JSON_ARRAY\" ...\n    \"JSON_ARRAYAGG\" ...\n    <LBRACE_FN> ...\n    \"MULTISET\" ...\n    \"ARRAY\" ...\n    \"PERIOD\" ...\n    \"ARRAY_CONCAT_AGG\" ...\n    \"GROUP_CONCAT\" ...\n    \"STRING_AGG\" ...\n    \"SPECIFIC\" ...\n    <IDENTIFIER> ...\n    <HYPHENATED_IDENTIFIER> ...\n    <QUOTED_IDENTIFIER> ...\n    <BACK_QUOTED_IDENTIFIER> ...\n    <BIG_QUERY_BACK_QUOTED_IDENTIFIER> ...\n    <BRACKET_QUOTED_IDENTIFIER> ...\n    <UNICODE_QUOTED_IDENTIFIER> ...\n    \"ABS\" ...\n    \"AVG\" ...\n    \"CARDINALITY\" ...\n    \"CHAR\" ...\n    \"CHAR_LENGTH\" ...\n    \"CHARACTER_LENGTH\" ...\n    \"COALESCE\" ...\n    \"COLLECT\" ...\n    \"COVAR_POP\" ...\n    \"COVAR_SAMP\" ...\n    \"CUME_DIST\" ...\n    \"COUNT\" ...\n    \"CURRENT_DATE\" ...\n    \"CURRENT_TIME\" ...\n    \"CURRENT_TIMESTAMP\" ...\n    \"DENSE_RANK\" ...\n    \"ELEMENT\" ...\n    \"EVERY\" ...\n    \"EXP\" ...\n    \"FIRST_VALUE\" ...\n    \"FUSION\" ...\n    \"INTERSECTION\" ...\n    \"GROUPING\" ...\n    \"HOUR\" ...\n    \"LAG\" ...\n    \"LEAD\" ...\n    \"LEFT\" ...\n    \"LAST_VALUE\" ...\n    \"LN\" ...\n    \"LOCALTIME\" ...\n    \"LOCALTIMESTAMP\" ...\n    \"LOWER\" ...\n    \"MAX\" ...\n    \"MIN\" ...\n    \"MINUTE\" ...\n    \"MOD\" ...\n    \"MONTH\" ...\n    \"NTH_VALUE\" ...\n    \"NTILE\" ...\n    \"NULLIF\" ...\n    \"OCTET_LENGTH\" ...\n    \"PERCENT_RANK\" ...\n    \"PERCENTILE_CONT\" ...\n    \"PERCENTILE_DISC\" ...\n    \"POWER\" ...\n    \"RANK\" ...\n    \"REGR_COUNT\" ...\n    \"REGR_SXX\" ...\n    \"REGR_SYY\" ...\n    \"RIGHT\" ...\n    \"ROW_NUMBER\" ...\n    \"SECOND\" ...\n    \"SOME\" ...\n    \"SQRT\" ...\n    \"STDDEV_POP\" ...\n    \"STDDEV_SAMP\" ...\n    \"SUM\" ...\n    \"UPPER\" ...\n    \"TRUNCATE\" ...\n    \"USER\" ...\n    \"VAR_POP\" ...\n    \"VAR_SAMP\" ...\n    \"YEAR\" ...\n    \"CURRENT_CATALOG\" ...\n    \"CURRENT_DEFAULT_TRANSFORM_GROUP\" ...\n    \"CURRENT_PATH\" ...\n    \"CURRENT_ROLE\" ...\n    \"CURRENT_SCHEMA\" ...\n    \"CURRENT_USER\" ...\n    \"SESSION_USER\" ...\n    \"SYSTEM_USER\" ...\n    \"NEW\" ...\n    \"CASE\" ...\n    \"CURRENT\" ...\n    \n\tat io.confluent.flink.plugin.internal.DefaultPluginContext.lambda$statementStatusCondition$10(DefaultPluginContext.java:529)\n\tat io.confluent.flink.plugin.internal.DefaultPluginContext.submitStatement(DefaultPluginContext.java:417)\n\tat io.confluent.flink.plugin.internal.DefaultPluginContext.queryCollect(DefaultPluginContext.java:234)\n\tat io.confluent.flink.plugin.internal.ConfluentExecutor.executeCollect(ConfluentExecutor.java:111)\n\tat io.confluent.flink.plugin.internal.ConfluentExecutor.executeAsync(ConfluentExecutor.java:84)\n\tat org.apache.flink.table.executor.python.ChainingOptimizingExecutor.executeAsync(ChainingOptimizingExecutor.java:88)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeQueryOperation(TableEnvironmentImpl.java:1072)\n\t... 14 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTableException\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m table = env.from_path(\u001b[33m\"\u001b[39m\u001b[33m`system.usage`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m result = table \\\n\u001b[32m     18\u001b[39m     .select(col(\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m)) \\\n\u001b[32m     19\u001b[39m     .limit(\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mConfluentTools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_changelog_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-flink/lib/python3.11/site-packages/pyflink/table/confluent/confluent_tools.py:114\u001b[39m, in \u001b[36mConfluentTools.print_changelog_limit\u001b[39m\u001b[34m(table, stop_after)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    113\u001b[39m   j_object = table._j_table_result\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[43mgateway\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfluentTools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprintChangelog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_after\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-flink/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-flink/lib/python3.11/site-packages/pyflink/util/exceptions.py:158\u001b[39m, in \u001b[36mcapture_java_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m java_exception\n",
      "\u001b[31mTableException\u001b[39m: org.apache.flink.table.api.TableException: Failed to execute sql\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeQueryOperation(TableEnvironmentImpl.java:1094)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1134)\n\tat org.apache.flink.table.api.internal.TableImpl.execute(TableImpl.java:477)\n\tat io.confluent.flink.plugin.ConfluentTools.printChangelog(ConfluentTools.java:171)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)\n\tat org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: io.confluent.flink.plugin.ConfluentFlinkException: Statement 'table-api-2025-11-20-022347-f1f177f0-43c6-4601-b198-1e01324087c5-api' failed.\nReason: SQL parse failed. Incorrect syntax near the keyword 'OFFSET' at line 5, column 13.\nWas expecting one of:\n    \"CURSOR\" ...\n    \"EXISTS\" ...\n    \"NOT\" ...\n    \"ROW\" ...\n    \"UNIQUE\" ...\n    \"(\" ...\n    \"+\" ...\n    \"-\" ...\n    \"INTERVAL\" ...\n    <UNSIGNED_INTEGER_LITERAL> ...\n    <DECIMAL_NUMERIC_LITERAL> ...\n    <APPROX_NUMERIC_LITERAL> ...\n    <BINARY_STRING_LITERAL> ...\n    <PREFIXED_STRING_LITERAL> ...\n    <QUOTED_STRING> ...\n    <UNICODE_STRING_LITERAL> ...\n    <BIG_QUERY_DOUBLE_QUOTED_STRING> ...\n    <BIG_QUERY_QUOTED_STRING> ...\n    \"TRUE\" ...\n    \"FALSE\" ...\n    \"UNKNOWN\" ...\n    \"NULL\" ...\n    <LBRACE_D> ...\n    <LBRACE_T> ...\n    <LBRACE_TS> ...\n    \"DATE\" ...\n    \"TIME\" ...\n    \"TIMESTAMP\" ...\n    \"?\" ...\n    \"CAST\" ...\n    \"EXTRACT\" ...\n    \"POSITION\" ...\n    \"CONVERT\" ...\n    \"TRANSLATE\" ...\n    \"OVERLAY\" ...\n    \"FLOOR\" ...\n    \"CEIL\" ...\n    \"CEILING\" ...\n    \"SUBSTRING\" ...\n    \"TRIM\" ...\n    \"CLASSIFIER\" ...\n    \"MATCH_NUMBER\" ...\n    \"RUNNING\" ...\n    \"PREV\" ...\n    \"NEXT\" ...\n    \"JSON_EXISTS\" ...\n    \"JSON_VALUE\" ...\n    \"JSON_QUERY\" ...\n    \"JSON_OBJECT\" ...\n    \"JSON_OBJECTAGG\" ...\n    \"JSON_ARRAY\" ...\n    \"JSON_ARRAYAGG\" ...\n    <LBRACE_FN> ...\n    \"MULTISET\" ...\n    \"ARRAY\" ...\n    \"PERIOD\" ...\n    \"ARRAY_CONCAT_AGG\" ...\n    \"GROUP_CONCAT\" ...\n    \"STRING_AGG\" ...\n    \"SPECIFIC\" ...\n    <IDENTIFIER> ...\n    <HYPHENATED_IDENTIFIER> ...\n    <QUOTED_IDENTIFIER> ...\n    <BACK_QUOTED_IDENTIFIER> ...\n    <BIG_QUERY_BACK_QUOTED_IDENTIFIER> ...\n    <BRACKET_QUOTED_IDENTIFIER> ...\n    <UNICODE_QUOTED_IDENTIFIER> ...\n    \"ABS\" ...\n    \"AVG\" ...\n    \"CARDINALITY\" ...\n    \"CHAR\" ...\n    \"CHAR_LENGTH\" ...\n    \"CHARACTER_LENGTH\" ...\n    \"COALESCE\" ...\n    \"COLLECT\" ...\n    \"COVAR_POP\" ...\n    \"COVAR_SAMP\" ...\n    \"CUME_DIST\" ...\n    \"COUNT\" ...\n    \"CURRENT_DATE\" ...\n    \"CURRENT_TIME\" ...\n    \"CURRENT_TIMESTAMP\" ...\n    \"DENSE_RANK\" ...\n    \"ELEMENT\" ...\n    \"EVERY\" ...\n    \"EXP\" ...\n    \"FIRST_VALUE\" ...\n    \"FUSION\" ...\n    \"INTERSECTION\" ...\n    \"GROUPING\" ...\n    \"HOUR\" ...\n    \"LAG\" ...\n    \"LEAD\" ...\n    \"LEFT\" ...\n    \"LAST_VALUE\" ...\n    \"LN\" ...\n    \"LOCALTIME\" ...\n    \"LOCALTIMESTAMP\" ...\n    \"LOWER\" ...\n    \"MAX\" ...\n    \"MIN\" ...\n    \"MINUTE\" ...\n    \"MOD\" ...\n    \"MONTH\" ...\n    \"NTH_VALUE\" ...\n    \"NTILE\" ...\n    \"NULLIF\" ...\n    \"OCTET_LENGTH\" ...\n    \"PERCENT_RANK\" ...\n    \"PERCENTILE_CONT\" ...\n    \"PERCENTILE_DISC\" ...\n    \"POWER\" ...\n    \"RANK\" ...\n    \"REGR_COUNT\" ...\n    \"REGR_SXX\" ...\n    \"REGR_SYY\" ...\n    \"RIGHT\" ...\n    \"ROW_NUMBER\" ...\n    \"SECOND\" ...\n    \"SOME\" ...\n    \"SQRT\" ...\n    \"STDDEV_POP\" ...\n    \"STDDEV_SAMP\" ...\n    \"SUM\" ...\n    \"UPPER\" ...\n    \"TRUNCATE\" ...\n    \"USER\" ...\n    \"VAR_POP\" ...\n    \"VAR_SAMP\" ...\n    \"YEAR\" ...\n    \"CURRENT_CATALOG\" ...\n    \"CURRENT_DEFAULT_TRANSFORM_GROUP\" ...\n    \"CURRENT_PATH\" ...\n    \"CURRENT_ROLE\" ...\n    \"CURRENT_SCHEMA\" ...\n    \"CURRENT_USER\" ...\n    \"SESSION_USER\" ...\n    \"SYSTEM_USER\" ...\n    \"NEW\" ...\n    \"CASE\" ...\n    \"CURRENT\" ...\n    \n\tat io.confluent.flink.plugin.internal.DefaultPluginContext.lambda$statementStatusCondition$10(DefaultPluginContext.java:529)\n\tat io.confluent.flink.plugin.internal.DefaultPluginContext.submitStatement(DefaultPluginContext.java:417)\n\tat io.confluent.flink.plugin.internal.DefaultPluginContext.queryCollect(DefaultPluginContext.java:234)\n\tat io.confluent.flink.plugin.internal.ConfluentExecutor.executeCollect(ConfluentExecutor.java:111)\n\tat io.confluent.flink.plugin.internal.ConfluentExecutor.executeAsync(ConfluentExecutor.java:84)\n\tat org.apache.flink.table.executor.python.ChainingOptimizingExecutor.executeAsync(ChainingOptimizingExecutor.java:88)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.executeQueryOperation(TableEnvironmentImpl.java:1072)\n\t... 14 more\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pyflink.table.confluent import ConfluentSettings, ConfluentTools\n",
    "from pyflink.table import TableEnvironment\n",
    "from pyflink.table.expressions import col\n",
    "\n",
    "# Load credentials\n",
    "load_dotenv()\n",
    "\n",
    "# Create TableEnvironment (NOT StreamExecutionEnvironment)\n",
    "settings = ConfluentSettings.from_global_variables()\n",
    "env = TableEnvironment.create(settings)\n",
    "env.use_catalog(\"msds682\")\n",
    "env.use_database(\"msds682\")\n",
    "# Use Table API\n",
    "table = env.from_path(\"`system.usage`\")\n",
    "\n",
    "result = table \\\n",
    "    .select(col('*')) \\\n",
    "    .limit(10)\n",
    "\n",
    "ConfluentTools.print_changelog_limit(result, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58212fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4994950",
   "metadata": {},
   "outputs": [
    {
     "ename": "TableException",
     "evalue": "org.apache.flink.table.api.TableException: Could not instantiate the executor. Make sure a planner module is on the classpath\n\tat org.apache.flink.table.api.bridge.internal.AbstractStreamTableEnvironmentImpl.lookupExecutor(AbstractStreamTableEnvironmentImpl.java:109)\n\tat org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.create(StreamTableEnvironmentImpl.java:110)\n\tat org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:122)\n\tat org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:94)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)\n\tat org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: org.apache.flink.table.api.ValidationException: Multiple factories for identifier 'default' that implement 'org.apache.flink.table.delegation.ExecutorFactory' found in the classpath.\n\nAmbiguous factory classes are:\n\nio.confluent.flink.plugin.internal.ConfluentExecutorFactory\norg.apache.flink.table.planner.loader.DelegateExecutorFactory\n\tat org.apache.flink.table.factories.FactoryUtil.discoverFactory(FactoryUtil.java:639)\n\tat org.apache.flink.table.api.bridge.internal.AbstractStreamTableEnvironmentImpl.lookupExecutor(AbstractStreamTableEnvironmentImpl.java:106)\n\t... 14 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mTableException\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m t_env = \u001b[43mStreamTableEnvironment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-flink/lib/python3.11/site-packages/pyflink/table/table_environment.py:1717\u001b[39m, in \u001b[36mStreamTableEnvironment.create\u001b[39m\u001b[34m(stream_execution_environment, environment_settings)\u001b[39m\n",
      "\u001b[32m   1713\u001b[39m         j_tenv = gateway.jvm.StreamTableEnvironment.create(\n",
      "\u001b[32m   1714\u001b[39m             stream_execution_environment._j_stream_execution_environment,\n",
      "\u001b[32m   1715\u001b[39m             environment_settings._j_environment_settings)\n",
      "\u001b[32m   1716\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1717\u001b[39m     j_tenv = \u001b[43mgateway\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreamTableEnvironment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_execution_environment\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_j_stream_execution_environment\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1720\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StreamTableEnvironment(j_tenv)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-flink/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n",
      "\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n",
      "\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n",
      "\u001b[32m   1318\u001b[39m     args_command +\\\n",
      "\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n",
      "\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/msds682-flink/lib/python3.11/site-packages/pyflink/util/exceptions.py:158\u001b[39m, in \u001b[36mcapture_java_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n",
      "\u001b[32m    156\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m java_exception\n",
      "\n",
      "\u001b[31mTableException\u001b[39m: org.apache.flink.table.api.TableException: Could not instantiate the executor. Make sure a planner module is on the classpath\n",
      "\tat org.apache.flink.table.api.bridge.internal.AbstractStreamTableEnvironmentImpl.lookupExecutor(AbstractStreamTableEnvironmentImpl.java:109)\n",
      "\tat org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.create(StreamTableEnvironmentImpl.java:110)\n",
      "\tat org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:122)\n",
      "\tat org.apache.flink.table.api.bridge.java.StreamTableEnvironment.create(StreamTableEnvironment.java:94)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.flink.table.api.ValidationException: Multiple factories for identifier 'default' that implement 'org.apache.flink.table.delegation.ExecutorFactory' found in the classpath.\n",
      "\n",
      "Ambiguous factory classes are:\n",
      "\n",
      "io.confluent.flink.plugin.internal.ConfluentExecutorFactory\n",
      "org.apache.flink.table.planner.loader.DelegateExecutorFactory\n",
      "\tat org.apache.flink.table.factories.FactoryUtil.discoverFactory(FactoryUtil.java:639)\n",
      "\tat org.apache.flink.table.api.bridge.internal.AbstractStreamTableEnvironmentImpl.lookupExecutor(AbstractStreamTableEnvironmentImpl.java:106)\n",
      "\t... 14 more\n"
     ]
    }
   ],
   "source": [
    "t_env = StreamTableEnvironment.create(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds682-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
